{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: kilian (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kilian/ann_mnist/runs/10b6nu7t\" target=\"_blank\">robust-night-4</a></strong> to <a href=\"https://wandb.ai/kilian/ann_mnist\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/kilian/ann_mnist/runs/10b6nu7t?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f54e89e4880>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "config = {\n",
    "    'log_interval': 1,\n",
    "}\n",
    "wandb.init(project=\"ann_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest2 = np.fromfile('xTest2.bin', dtype=np.uint8)\n",
    "xTest2 = xTest2.reshape([28, 28, 1, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest2[:,:,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_valset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(mnist_trainset,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(mnist_valset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAANXUlEQVR4nO3dXaxV9ZnH8d9vGPAFesGLIEMZZaoXGjFAiDGhx9RUGjUm2AsnhUSZDPHUBMeaSBzSuajJqEFnOkZvGg+pwkwYGhJ1NM1kWkKawYlJ9UgY5cUiUxEoJxwZLgo3VuCZi7PO5BTOXvuw1957bc7z/SQne+/17LXW444/1tve6++IEIDJ70/qbgBAdxB2IAnCDiRB2IEkCDuQxJ92c2W2OfUPdFhEeLzplbbstu+1/Rvbh21vrLIsAJ3lVq+z254i6ZCklZKOS/pA0uqIOFAyD1t2oMM6sWW/Q9LhiPhtRPxB0s8kraqwPAAdVCXsCyQdG/P6eDHtj9jutz1oe7DCugBUVOUE3Xi7CpfspkfEgKQBid14oE5VtuzHJS0c8/rrkk5UawdAp1QJ+weSbra9yPY0Sd+T9E572gLQbi3vxkfEOduPS/qFpCmSXouI/W3rDEBbtXzpraWVccwOdFxHvlQD4MpB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii5fHZJcn2EUlnJJ2XdC4ilrejKQDtVynshbsj4lQblgOgg9iNB5KoGvaQ9EvbH9ruH+8NtvttD9oerLguABU4Ilqf2f6ziDhhe66knZL+JiJ2l7y/9ZUBmJCI8HjTK23ZI+JE8Tgs6S1Jd1RZHoDOaTnstqfb/troc0nfkbSvXY0BaK8qZ+PnSXrL9uhy/jUi/qMtXQFou0rH7Je9Mo7ZgY7ryDE7gCsHYQeSIOxAEoQdSIKwA0m044cwk8L06dNL61dffXXD2gMPPFA675IlS1rqaTJ45ZVXGtY+++yzLnYCtuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMSk+dXbmjVrSusrVqyoVF+8ePFl9wTp8OHDDWt9fX2l8w4PD7e7nRT41RuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJDFprrM3+++4cOFCpfqxY8cuu6dR7777bmn9iy++KK0fPHiw5XVXddttt5XWn3jiiZaXvWHDhtL6Sy+91PKyM+M6O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kMWnuG3/o0KHS+pdffllaf/bZZ0vrO3bsuOyergQLFy4srd91110dW/fnn3/esWXjUk237LZfsz1se9+YabNs77T9afE4s7NtAqhqIrvxWyTde9G0jZJ2RcTNknYVrwH0sKZhj4jdkk5fNHmVpK3F862SHmxzXwDarNVj9nkRMSRJETFke26jN9rul9Tf4noAtEnHT9BFxICkAamzP4QBUK7VS28nbc+XpOKR24ACPa7VsL8jaW3xfK2kt9vTDoBOafp7dtvbJX1L0hxJJyX9SNK/Sdoh6c8lHZX0UERcfBJvvGWxG99lixYtKq03+/7AsmXLKq3/7bcbbwfWrl3bsCZJZ86cqbTurBr9nr3pMXtErG5Q+naljgB0FV+XBZIg7EAShB1IgrADSRB2IIlJcyvpyezaa68trd9zzz0NawMDA6XzXnfddS31NFG33357w9r+/fs7uu6suJU0kBxhB5Ig7EAShB1IgrADSRB2IAnCDiTBdfYrwIsvvlhaf+qpp7rUyeUrG6767NmzlZY9ODhYWt+yZUvD2pEjRyqtu5dxnR1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkpg0QzZPZjfddFPdLbSsr6+vY8u+7777Suu33HJLw9qaNWtK5z1//nxLPfUytuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kAS/Z78C3HrrraX12bNnd6mTS82dO7e0/vDDDzesvf7666Xz3nDDDaX1F154obQ+bdq0hrX33nuvdN677767tH7u3LnSep1a/j277ddsD9veN2baM7Z/Z3tv8Xd/O5sF0H4T2Y3fIunecaa/FBFLir9/b29bANqtadgjYrek013oBUAHVTlB97jtj4rd/JmN3mS73/ag7fIbhgHoqFbD/hNJ35C0RNKQpB83emNEDETE8ohY3uK6ALRBS2GPiJMRcT4iLkjaLOmO9rYFoN1aCrvt+WNeflfSvkbvBdAbml5nt71d0rckzZF0UtKPitdLJIWkI5K+HxFDTVfGdfYrzooVK0rrzz33XGn9kUceaVg7evRoSz2NWrZsWWn91VdfbXnexYsXl9YPHDhQWq9To+vsTW9eERGrx5n808odAegqvi4LJEHYgSQIO5AEYQeSIOxAEtxKOrk777yztL5p06bS+tNPP11ar3p5rcyePXtK69u2bWtYa3bpbefOnaX1BQsWlNZ7EVt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC6+zJbdiwobR+zTXXlNY/+eSTdrbTVu+//37D2ldffVU67/XXX9/udmrHlh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuA6e3Jz5swprS9durS0vn379tL6888/37C2e/fu0nmbeeihh0rrq1atalibOnVqpXVfidiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASXGdPbu/evaX1vr6+0vrKlStL62VDPp86dap03maa3bt9ypQpLS973bp1Lc/bq5pu2W0vtP0r2wdt77f9g2L6LNs7bX9aPM7sfLsAWjWR3fhzkp6KiFsk3Slpve1bJW2UtCsibpa0q3gNoEc1DXtEDEXEnuL5GUkHJS2QtErS1uJtWyU92KkmAVR3Wcfstm+UtFTSryXNi4ghaeQfBNtzG8zTL6m/WpsAqppw2G3PkPSGpCcj4ve2JzRfRAxIGiiWEa00CaC6CV16sz1VI0HfFhFvFpNP2p5f1OdLGu5MiwDawRHlG1uPbMK3SjodEU+Omf4Pkv43IjbZ3ihpVkSUjt/Llr33XHXVVaX1l19+ubT+6KOPtrOdrtm8eXNpff369aX18+fPt7OdtoqIcXe7J7Ibv0LSw5I+tj16UfaHkjZJ2mF7naSjksp/XAygVk3DHhH/JanRAfq329sOgE7h67JAEoQdSIKwA0kQdiAJwg4k0fQ6e1tXxnX2K860adNK6zNmzCitP/bYYw1rs2fPbqmniSobsnnHjh2l83YzF+3W6Do7W3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILr7MAkw3V2IDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKJp2G0vtP0r2wdt77f9g2L6M7Z/Z3tv8Xd/59sF0KqmN6+wPV/S/IjYY/trkj6U9KCkv5R0NiL+ccIr4+YVQMc1unnFRMZnH5I0VDw/Y/ugpAXtbQ9Ap13WMbvtGyUtlfTrYtLjtj+y/ZrtmQ3m6bc9aHuwUqcAKpnwPehsz5D0n5Kei4g3bc+TdEpSSPp7jezq/3WTZbAbD3RYo934CYXd9lRJP5f0i4j4p3HqN0r6eUTc1mQ5hB3osJZvOGnbkn4q6eDYoBcn7kZ9V9K+qk0C6JyJnI3/pqR3JX0s6UIx+YeSVktaopHd+COSvl+czCtbFlt2oMMq7ca3C2EHOo/7xgPJEXYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JoesPJNjsl6fMxr+cU03pRr/bWq31J9NaqdvZ2Q6NCV3/PfsnK7cGIWF5bAyV6tbde7Uuit1Z1qzd244EkCDuQRN1hH6h5/WV6tbde7Uuit1Z1pbdaj9kBdE/dW3YAXULYgSRqCbvte23/xvZh2xvr6KER20dsf1wMQ13r+HTFGHrDtveNmTbL9k7bnxaP446xV1NvPTGMd8kw47V+dnUPf971Y3bbUyQdkrRS0nFJH0haHREHutpIA7aPSFoeEbV/AcP2XZLOSvrn0aG1bL8o6XREbCr+oZwZEX/bI709o8scxrtDvTUaZvyvVONn187hz1tRx5b9DkmHI+K3EfEHST+TtKqGPnpeROyWdPqiyaskbS2eb9XI/yxd16C3nhARQxGxp3h+RtLoMOO1fnYlfXVFHWFfIOnYmNfH1VvjvYekX9r+0HZ/3c2MY97oMFvF49ya+7lY02G8u+miYcZ75rNrZfjzquoI+3hD0/TS9b8VEbFM0n2S1he7q5iYn0j6hkbGAByS9OM6mymGGX9D0pMR8fs6exlrnL668rnVEfbjkhaOef11SSdq6GNcEXGieByW9JZGDjt6ycnREXSLx+Ga+/l/EXEyIs5HxAVJm1XjZ1cMM/6GpG0R8WYxufbPbry+uvW51RH2DyTdbHuR7WmSvifpnRr6uITt6cWJE9meLuk76r2hqN+RtLZ4vlbS2zX28kd6ZRjvRsOMq+bPrvbhzyOi63+S7tfIGfn/kfR3dfTQoK+/kPTfxd/+unuTtF0ju3VfaWSPaJ2k2ZJ2Sfq0eJzVQ739i0aG9v5II8GaX1Nv39TIoeFHkvYWf/fX/dmV9NWVz42vywJJ8A06IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUji/wCNPTdXxbZbYAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilian/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:54: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show images\n",
    "idx = 30\n",
    "imshow(torchvision.utils.make_grid(train_dataloader.dataset.data[idx]))\n",
    "train_dataloader.dataset.train_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(864,32)\n",
    "        self.fc2 = nn.Linear(32, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Magic\n",
    "wandb.watch(net, log_freq=100)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        if i % config['log_interval'] == 0:\n",
    "            wandb.log({\"loss\": loss})\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.97\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: {}'.format(\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0 is: 98.5 %\n",
      "Accuracy for class 1 is: 97.3 %\n",
      "Accuracy for class 2 is: 98.2 %\n",
      "Accuracy for class 3 is: 94.9 %\n",
      "Accuracy for class 4 is: 98.2 %\n",
      "Accuracy for class 5 is: 96.0 %\n",
      "Accuracy for class 6 is: 94.9 %\n",
      "Accuracy for class 7 is: 92.8 %\n",
      "Accuracy for class 8 is: 96.3 %\n",
      "Accuracy for class 9 is: 92.8 %\n"
     ]
    }
   ],
   "source": [
    "targets = val_dataloader.dataset.targets.unique().numpy()\n",
    "targets_correct = {target: 0 for target in targets}\n",
    "targets_count = {target: 0 for target in targets}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in val_dataloader:\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs.data, 1)\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                targets_correct[targets[label]] += 1\n",
    "            targets_count[targets[label]] += 1\n",
    "\n",
    "for classname, correct_count in targets_correct.items():\n",
    "    accuracy = 100 * float(correct_count) / targets_count[classname]\n",
    "    print(\"Accuracy for class {} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
